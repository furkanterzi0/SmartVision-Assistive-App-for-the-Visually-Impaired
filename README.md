# VisionAid - AI-Powered Assistant for the Visually Impaired ğŸ‘ï¸â€ğŸ—¨ï¸

A mobile application built to support visually impaired individuals in navigating their environment safely and independently. The app integrates real-time object detection, traffic light classification, and full voice feedback using machine learning technologies.

## ğŸš€ Features

- ğŸ”Š **Voice-Driven Interface**: Start the app with a single touch, no need to see the screen.
- ğŸ’¡ **Automatic Flashlight**: Detects ambient light and turns on flashlight when needed.
- ğŸš¦ **Traffic Light Recognition**: Detects red or green lights and announces the result using voice.
- ğŸ¦º **Environmental Object Detection**: Double-tap the screen to activate "Safe Mode" which scans and announces nearby objects.
- âœ‹ **Safe Exit**: Triple-tap for secure exit from the application.
- ğŸ¯ **Optional Object Detection Mode**: On-demand object identification around the user.
- ğŸ¨ **Minimal & Accessible UI**: Clean, voice-guided design optimized for accessibility.

## ğŸ§  Technologies Used

- **TensorFlow Lite** â€“ Model deployment on Android
- **SSD MobileNet V1** â€“ Real-time object detection
- **Custom CNN Model** â€“ For traffic light classification
- **Kotlin** â€“ Android development
- **OpenCV** â€“ Image processing
- **Text-to-Speech (TTS)** â€“ For all voice feedback


## ğŸ“¸ Screenshots

| Startup Screen | Traffic Light Detection | Object Detection | Safe Mode Active |
|----------------|-------------------------|------------------|------------------|
| ![](screenshots/startActivity.png) | ![](screenshots/mainActivity.png) | ![](screenshots/trfclght.png) | ![](screenshots/object.png) |
